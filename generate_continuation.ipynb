{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audiocraft-mps debugging notebook\n",
    "\n",
    "### locally executed environment\n",
    "- macOS(M1 Pro): Ventura 13.5.1\n",
    "- Python: 3.11.4\n",
    "\n",
    "### Setup\n",
    "\n",
    "To install audiocraft, please check the [official documentation](https://github.com/facebookresearch/audiocraft).\n",
    "\n",
    "note: Updateing masOS to >=13.0 is required to run LSTM models in mps.\n",
    "\n",
    "Run these commands before implementing this notebook.\n",
    "```sh-session\n",
    "$conda env config vars set PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "$conda activate <AUDIOCRAFT_VIRTUAL_ENV>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[43083]: Class AVFFrameReceiver is implemented in both /Users/ebarakoji/miniforge3/envs/audiogen/lib/libavdevice.58.8.100.dylib (0x1089a0798) and /Users/ebarakoji/miniforge3/envs/audiogen/lib/python3.11/site-packages/av/.dylibs/libavdevice.59.7.100.dylib (0x168cf8778). One of the two will be used. Which one is undefined.\n",
      "objc[43083]: Class AVFAudioReceiver is implemented in both /Users/ebarakoji/miniforge3/envs/audiogen/lib/libavdevice.58.8.100.dylib (0x1089a07e8) and /Users/ebarakoji/miniforge3/envs/audiogen/lib/python3.11/site-packages/av/.dylibs/libavdevice.59.7.100.dylib (0x168cf87c8). One of the two will be used. Which one is undefined.\n",
      "/Users/ebarakoji/miniforge3/envs/audiogen/lib/python3.11/site-packages/torch/nn/init.py:46: UserWarning: The operator 'aten::erfinv.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  tensor.erfinv_()\n"
     ]
    }
   ],
   "source": [
    "from audiocraft.models import AudioGen\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "cpu_model = AudioGen.get_pretrained('facebook/audiogen-medium', device='cpu')\n",
    "mps_model = AudioGen.get_pretrained('facebook/audiogen-medium', device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "\n",
    "prompt_path = os.path.join(os.path.abspath(os.pardir), 'examples', 'outputs', 'crow.wav')\n",
    "prompt, sample_rate = torchaudio.load(prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting use_sampling to False to see whether gen_tokens are the same, but this causes deteriorated sounds.\n",
    "gen_params_dict = {\n",
    "    'use_sampling': False,\n",
    "    'top_k': 250,\n",
    "}\n",
    "\n",
    "cpu_model.set_generation_params(**gen_params_dict)\n",
    "mps_model.set_generation_params(**gen_params_dict)\n",
    "\n",
    "\n",
    "gen_args = {\n",
    "    'prompt': prompt,\n",
    "    'prompt_sample_rate': sample_rate,\n",
    "    'descriptions': ['A crow is cawing'],\n",
    "    'progress': True,\n",
    "    'debug_tokens': True,\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   253 /    500\r"
     ]
    }
   ],
   "source": [
    "# changed the generate function to return the tuple of (output, prompt_tokens, gen_tokens) to inspect decoder\n",
    "cpu_output, cpu_prompt_tokens, cpu_gen_tokens = cpu_model.generate_continuation(**gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   253 /    500\r"
     ]
    }
   ],
   "source": [
    "mps_output, mps_prompt_tokens, mps_gen_tokens = mps_model.generate_continuation(**gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cpu_output == mps_output.to('cpu')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cpu_gen_tokens == mps_gen_tokens.to('cpu')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cpu_prompt_tokens == mps_prompt_tokens.to('cpu')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cpu_x, cpu_scale = cpu_model.compression_model.preprocess(prompt[None])\n",
    "mps_x, mps_scale = mps_model.compression_model.preprocess(prompt[None].to('mps'))\n",
    "\n",
    "print((cpu_x == mps_x.to('mps').to('cpu')).all())\n",
    "print(cpu_scale == mps_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_emb = cpu_model.compression_model.encoder(cpu_x)\n",
    "mps_emb = mps_model.compression_model.encoder(mps_x).to('cpu')\n",
    "(cpu_emb == mps_emb.to('cpu')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_codes = cpu_model.compression_model.quantizer.encode(cpu_emb)\n",
    "mps_codes = mps_model.compression_model.quantizer.encode(cpu_emb.to('mps')).to('cpu')\n",
    "\n",
    "(cpu_codes == mps_codes.to('cpu')).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
